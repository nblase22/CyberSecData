{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import session\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create spark app\n",
    "spark = SparkSession.builder.appName('test').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+----------------+\n",
      "|Time|SourceComputer|ComputerResolved|\n",
      "+----+--------------+----------------+\n",
      "|   2|         C4653|           C5030|\n",
      "|   2|         C5782|          C16712|\n",
      "|   6|         C1191|            C419|\n",
      "|  15|         C3380|          C22841|\n",
      "|  18|         C2436|           C5030|\n",
      "+----+--------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the DNS csv into a spark dataframe, rename columns\n",
    "dns_df = spark.read.format(\"csv\").option(\"header\", \"false\").load(\"./Data/CSVs/dns.csv\")\n",
    "dns_df = dns_df.selectExpr(\"_c0 as Time\", \"_c1 as SourceComputerDNS\", \"_c2 as ComputerResolved\")\n",
    "dns_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------------+----------+-------------------+---------------+--------+-----------+---------+\n",
      "|Time|Duration|SourceComputer|SourcePort|DestinationComputer|DestinationPort|Protocol|PacketCount|ByteCount|\n",
      "+----+--------+--------------+----------+-------------------+---------------+--------+-----------+---------+\n",
      "|   1|       0|         C1065|       389|              C3799|         N10451|       6|         10|     5323|\n",
      "|   1|       0|         C1423|     N1136|              C1707|             N1|       6|          5|      847|\n",
      "|   1|       0|         C1423|     N1142|              C1707|             N1|       6|          5|      847|\n",
      "|   1|       0|        C14909|     N8191|              C5720|           2049|       6|          1|       52|\n",
      "|   1|       0|        C14909|     N8192|              C5720|           2049|       6|          1|       52|\n",
      "+----+--------+--------------+----------+-------------------+---------------+--------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the flows CSV into a spark dataframe, rename columns\n",
    "flows_df = spark.read.format(\"csv\").option(\"header\", \"false\").load(\"./Data/CSVs/flows.csv\")\n",
    "flows_df = flows_df.selectExpr(\"_c0 as Time\", \"_c1 as Duration\", \"_c2 as SourceComputerFlow\", \"_c3 as SourcePort\", \"_c4 as DestinationComputerFlow\", \"_c5 as DestinationPort\", \"_c6 as Protocol\", \"_c7 as PacketCount\", \"_c8 as ByteCount\")\n",
    "flows_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+--------+-----------+--------+\n",
      "|Time| UserDomain|Computer|ProcessName|StartEnd|\n",
      "+----+-----------+--------+-----------+--------+\n",
      "|   1|   C1$@DOM1|      C1|        P16|   Start|\n",
      "|   1|C1001$@DOM1|   C1001|         P4|   Start|\n",
      "|   1|C1002$@DOM1|   C1002|         P4|   Start|\n",
      "|   1|C1004$@DOM1|   C1004|         P4|   Start|\n",
      "|   1|C1017$@DOM1|   C1017|         P4|   Start|\n",
      "+----+-----------+--------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the proc CSV into a spark dataframe, rename columns\n",
    "proc_df = spark.read.format(\"csv\").option(\"header\", \"false\").load(\"./Data/CSVs/proc.csv\")\n",
    "proc_df = proc_df.selectExpr(\"_c0 as Time\", \"_c1 as UserDomainProc\", \"_c2 as ComputerProc\", \"_c3 as ProcessName\", \"_c4 as StartEnd\")\n",
    "proc_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------+-------------------+\n",
      "|  Time|UserDomain|SourceComputer|DestinationComputer|\n",
      "+------+----------+--------------+-------------------+\n",
      "|150885| U620@DOM1|        C17693|              C1003|\n",
      "|151036| U748@DOM1|        C17693|               C305|\n",
      "|151648| U748@DOM1|        C17693|               C728|\n",
      "|151993|U6115@DOM1|        C17693|              C1173|\n",
      "|153792| U636@DOM1|        C17693|               C294|\n",
      "+------+----------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the flows CSV into a spark dataframe, rename columns\n",
    "redteam_df = spark.read.format(\"csv\").option(\"header\", \"false\").load(\"./Data/CSVs/redteam.csv\")\n",
    "redteam_df = redteam_df.selectExpr(\"_c0 as Time\", \"_c1 as UserDomainRed\", \"_c2 as SourceComputerRed\", \"_c3 as DestinationComputerRed\")\n",
    "redteam_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stop spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
